{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185f377-f4d6-4fe4-8537-fc287cb2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "\n",
    "# Image processing tools\n",
    "import skimage.feature\n",
    "import skimage.filters\n",
    "import skimage.filters.rank\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import bokeh\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "import img_seg_package.single_image as si\n",
    "\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ee0fb-1e0e-461b-bc59-ad535c506893",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a method for generating the associated figures of the CAP-A4 manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1ab56-e2d8-4565-b9ce-0c43ff77a135",
   "metadata": {},
   "source": [
    "## Figure 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508ce98-8b72-406e-be83-53462418ab9b",
   "metadata": {},
   "source": [
    "First, we want to generate an overview of the lung. To do this, we can load in an image from..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b2568-b816-4c21-a19a-95b0e6a3f4a7",
   "metadata": {},
   "source": [
    "**Make an overview of the lung for Figure 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77106bcf-7cbf-4481-bdc3-40b166aded04",
   "metadata": {},
   "source": [
    "Next, we want to generate all the individual figures to demonstrate the workflow of the figure. To do this, we need to identify the location of the specific tissue image we want to examine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7abad-c14c-40e6-af70-c06469379e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall directory for the examined images\n",
    "data_dir = '../Lung_Paper_Images/Test_Images/'\n",
    "\n",
    "# The tissue examined for filename purposes\n",
    "tissue = 'Lung'\n",
    "\n",
    "# The variant being examined\n",
    "variant = 'CAPA4'\n",
    "\n",
    "# The animal being examined (integer for dataframe purposes)\n",
    "animal = 2\n",
    "\n",
    "# The replicate being examined (integer for dataframe purposes)\n",
    "replicate = 2\n",
    "\n",
    "# The name of the image being examined\n",
    "img_loc = '1_XY04_00065_Overlay'\n",
    "\n",
    "# The complete filename of the image being examined \n",
    "fname = data_dir + tissue + '/' + variant + '/' + str(animal) + '/' + str(replicate) + '/' + img_loc + '.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfdfd66-fcc4-44d4-a112-9f77fe061462",
   "metadata": {},
   "source": [
    "Next, we can load in the dataframe in which the data has been saved. From this dataframe we can extract all of the parameters used to analyze the whole tissue images and apply them to the individual images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3020e-7b65-4866-86bd-9ce5a9981a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the dataframe location, where it was previously saved it using the 'image_analysis.ipynb' notebook.\n",
    "dataframe_loc = '../Lung_Paper_Images/Quantification/Lung_Quantification.csv'\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.read_csv(dataframe_loc)\n",
    "\n",
    "# Set indices of the different identifying information to allow simple access of the data.\n",
    "inds = (df['Virus'] == variant) & (df['Animal'] == animal) & (df['Replicate'] == replicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f770a-49fb-4f74-9a55-2956b2d15bd7",
   "metadata": {},
   "source": [
    "Now that we have all of this information initialized, we can go through the analysis process to view the outcome of the major analysis steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0710ccf-af95-4a60-86b1-2699d56f30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the autofluorescence and signal images\n",
    "im_af = skimage.img_as_float(skimage.io.imread(fname)[:,:,0])\n",
    "im_sig = skimage.img_as_float(skimage.io.imread(fname)[:,:,1])\n",
    "\n",
    "#Get the image height and width data\n",
    "im_height = np.shape(im_sig)[0]\n",
    "im_width = np.shape(im_sig)[1]\n",
    "\n",
    "#Import the shape template and get the associated data\n",
    "template = np.load('../template.npy')\n",
    "template_height = np.shape(template)[0]\n",
    "template_width = np.shape(template)[1]\n",
    "\n",
    "#Save these initial images for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/autofluorescence_input.tif', im_af[300:800, 450:950])\n",
    "skimage.io.imsave('../Workflow_Figure/signal_input.tif', im_sig[300:800, 450:950])\n",
    "\n",
    "#Show these images\n",
    "bokeh.io.show(si.show_two_ims(im_af[300:800, 450:950], im_sig[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da8f21-687f-4c82-bf40-08ba26454841",
   "metadata": {},
   "source": [
    "Next, we can display the image with the two channels stacked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b74f5-7f55-45b4-80d2-ad0dafc73d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a stack of the three channels to create a magenta / green image, with labelled cells in green.\n",
    "im_magenta = np.dstack((im_af, im_sig, im_af))\n",
    "\n",
    "# Display the stacked image\n",
    "bokeh.io.show(si.imshow(im_magenta[300:800, 450:950], color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c62d3-3b20-4e61-b73f-9a751e484256",
   "metadata": {},
   "source": [
    "Now that we have our images loaded, we can start to perform the analysis processes on these images. The first thing we can do is to determine the tissue area within the examined tissue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579afd0-e970-4a6a-b51d-68d779b708b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the intensity threshold determined to dilineate background from tissue.\n",
    "threshed_single = im_af > df.loc[inds, 'Area Threshold'].values[0]\n",
    "skimage.io.imsave('../Workflow_Figure/tissue_area.tif', threshed_single[300:800, 450:950])\n",
    "\n",
    "bokeh.io.show(si.imshow(threshed_single[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd81a2-db32-4b79-9669-7622c6544ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can create the autofluorescence subtracted image\n",
    "im_sub = im_sig - im_af*df.loc[inds, 'Image Multiplication Factor'].values[0]\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/af_subtracted_image.tif', im_sub[300:800, 450:950])\n",
    "\n",
    "# Show the image\n",
    "bokeh.io.show(si.imshow(im_sub[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3ffda-f3d9-4be1-89cc-682104cd9ba9",
   "metadata": {},
   "source": [
    "We can see that subtraction does a really good job illuminating where the expressing cells are located. Next, we can examine the background subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb110ed-f0ca-406e-9f01-2aec2f5a5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can perform background subtraction\n",
    "im_bg = skimage.filters.gaussian(im_sub, df.loc[inds, 'Gaussian Size'].values[0], truncate = df.loc[inds, 'Truncation'].values[0])\n",
    "\n",
    "im_no_bg = im_sub - im_bg\n",
    "\n",
    "im_no_bg = (im_no_bg - df.loc[inds, 'Minimum Pixel Value'].values[0]) / (df.loc[inds, 'Maximum Pixel Value'].values[0] - df.loc[inds, 'Minimum Pixel Value'].values[0])\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/bg_subtracted_image.tif', im_no_bg[300:800, 450:950])\n",
    "\n",
    "# Show the image\n",
    "bokeh.io.show(si.imshow(im_no_bg[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da5bff-2fe3-48b6-ab36-3a10d48885a0",
   "metadata": {},
   "source": [
    "This image is a little smoother, and should be easier to identify the bright sections in. Next, we can do the feature matching on the subtracted image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60966af1-4afe-4b94-a6a5-0ddcc2c27794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform feature matching\n",
    "im_feat = skimage.feature.match_template(im_sub, template)\n",
    "\n",
    "#Display objects that pass the similarity threshold\n",
    "binary_thresh = im_feat > df.loc[inds, 'Size Threshold'].values[0]\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/feature_thresholding.tif', binary_thresh[300:800, 450:950])\n",
    "\n",
    "# Show the image\n",
    "bokeh.io.show(si.imshow(binary_thresh[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c561137-3778-4f4d-b39f-9fb2ddd2ba1e",
   "metadata": {},
   "source": [
    "These are all the positions that have features similar to our template. Next we want to determine which regions of the image are bright. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e91c1-839e-4e8b-ae31-816d71648e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the regions that are bright using the same intensity threhold as the large image. \n",
    "binary_intensity = im_no_bg[int(template_height/2 - 1):int(im_height - int(template_height/2)), int(template_width/2 - 1):int(im_width - int(template_width/2))] > df.loc[inds, 'Applied Threshold'].values[0]\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/intensity_thresholding.tif', binary_intensity[300:800, 450:950])\n",
    "\n",
    "# Show the image\n",
    "bokeh.io.show(si.imshow(binary_intensity[300:800, 450:950])) #, color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23439a8-3b24-4ecf-bcee-a9ce36bce062",
   "metadata": {},
   "source": [
    "These are all the bright regions in the image. There is definitely co-localization between these binary images, so we can multiply them together to determine regions that are both circular and bright. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339adaf7-5ff7-49e0-8abf-fb8279c0075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mult = binary_intensity*binary_thresh\n",
    "\n",
    "binary_rem = skimage.morphology.remove_small_objects(binary_mult, min_size=df.loc[inds, 'Minimum Size'].values[0])\n",
    "\n",
    "im_labeled, n_labels = skimage.measure.label(binary_rem, background=0, return_num=True)\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/intensity_thresholding.tif', im_labeled[300:800, 450:950])\n",
    "\n",
    "# Load phase image\n",
    "im_p = skimage.img_as_float(skimage.io.imread(fname))[:,:,:2][int(template_height/2 - 1):int(im_height - int(template_height/2)), int(template_width/2 - 1):int(im_width - int(template_width/2))]\n",
    "\n",
    "binary_rgb = np.dstack((binary_rem, binary_rem, binary_rem))\n",
    "\n",
    "#Save this image for the figure\n",
    "skimage.io.imsave('../Workflow_Figure/labeled_image.tif', binary_rgb[300:800, 450:950])\n",
    "\n",
    "# Show the image\n",
    "bokeh.io.show(si.imshow(binary_rgb[300:800, 450:950], color_mapper='rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c662f5-7fd0-41a5-8de5-b097a86a72dd",
   "metadata": {},
   "source": [
    "These are all the spots that pass both of our tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
